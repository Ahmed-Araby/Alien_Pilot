{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multi_model_multi_task_1_5_20__123.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VrB0iwfDKNF",
        "colab_type": "code",
        "outputId": "bb392a33-952e-4cf5-ef96-619fb6050c0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# change the version of tensorflow (default is 2.x)\n",
        "%tensorflow_version 1.x\n",
        "\n",
        "Learning_rate = 0.001\n",
        "Spliting_precentage = 0.1 \n",
        "Batch_size = 256  # *= Aug_out  **********\n",
        "Num_epochs = 30\n",
        "Time_steps = 20\n",
        "\n",
        "\n",
        "# may be he need to see more from the image to capture the speed information \n",
        "inputH = 100\n",
        "inputW = 320\n",
        "inputC = 3\n",
        "\n",
        "\n",
        "# Agumentation \n",
        "angle_shift = {\n",
        "    'center':0 ,\n",
        "    'left':0.25 ,\n",
        "    'right':-0.25\n",
        "}\n",
        "\n",
        "Salt_Precentage = 0.015\n",
        "Peper_Precentage = 0.030\n",
        "drop_out_region_precentage = 0.1\n",
        "\n",
        "H_angle_shift = 0.0035 \n",
        "H_shift_low  = -60\n",
        "H_shift_high = 61\n",
        "\n",
        "CNN_reg_val = 0\n",
        "FC_reg_val = 0\n",
        "FC_drop_val = 0.5\n",
        "\n",
        "Aug_out = 12\n",
        "\n",
        "Train_file_name = \"my_data9/driving_log.csv\"\n",
        "Valid_file_name =  \"data/driving_log.csv\"\n",
        "N_file_name =  \"hard/driving_log.csv\"\n",
        "\n",
        "Model_name = \"Multi_model_model.h5\"\n",
        "Data_link = 'https://s3.amazonaws.com/video.udacity-data.com/topher/2016/December/584f6edd_data/data.zip'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EM3cr5d77tR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#imports \n",
        "import matplotlib.pyplot as plt\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43gH8ijJNcXu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Utils \n",
        "\n",
        "# custom call backs \n",
        "\n",
        "import tensorflow as tf \n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import keras \n",
        "import os \n",
        "class MyCustomCallback(keras.callbacks.Callback):\n",
        "    def on_epoch_end(self , epoch , logs=None):\n",
        "          name = 'FMulti_model'\n",
        "          if not os.path.isfile(name+'.h5'):\n",
        "              print(\"file is not exist :{}\".format(name))\n",
        "              return\n",
        "\n",
        "          print(\"saving model\" , name +'.h5' , '.............')\n",
        "          auth.authenticate_user()\n",
        "          gauth = GoogleAuth()\n",
        "          gauth.credentials = GoogleCredentials.get_application_default()\n",
        "          drive = GoogleDrive(gauth)\n",
        "\n",
        "          # 2. Save Keras Model or weights on google drive\n",
        "          # create on Colab directory\n",
        "          save_name = name + \"_\" + str(epoch) + \"_605_\" +'.h5'\n",
        "          file_name = name + '.h5'\n",
        "\n",
        "          model_file = drive.CreateFile({'title' : save_name})\n",
        "          model_file.SetContentString(file_name) # was the issue \n",
        "          model_file.Upload()\n",
        "          print(\"successfull saved to drive at {}\".format(\"ahmedaraby605@gmail.com\"))\n",
        "          return\n",
        "\n",
        "# freeze model layers \n",
        "def freeze(model):\n",
        "    model_layers = []\n",
        "    model_layers.append(model.get_layer('angle_out'))\n",
        "    model_layers.append(model.get_layer('anglefc1'))\n",
        "    model_layers.append(model.get_layer('anglefc2'))\n",
        "    model_layers.append(model.get_layer('anglefc3'))\n",
        "\n",
        "    model_layers.append(model.get_layer('cnn1'))\n",
        "    model_layers.append(model.get_layer('cnn2'))\n",
        "    model_layers.append(model.get_layer('cnn3'))\n",
        "    model_layers.append(model.get_layer('cnn4'))\n",
        "    model_layers.append(model.get_layer('cnn5'))\n",
        "\n",
        "    for layer in model_layers:\n",
        "      print(layer)\n",
        "      # by reference\n",
        "      layer.trainable = False\n",
        "    return \n",
        "\n",
        "def save_file(X , name):\n",
        "    with open(name , 'wb') as f:\n",
        "      pickle.dump(X , f)\n",
        "    return \n",
        "    \n",
        "def download_unzip_data():\n",
        "    # download the data \n",
        "    from urllib.request import urlretrieve\n",
        "    import os\n",
        "    def download(url, file):\n",
        "        if not os.path.isfile(file):\n",
        "            print(\"D  ownload file... \" + file + \" ...\")\n",
        "            urlretrieve(url,file)\n",
        "            print(\"File downloaded\")\n",
        "\n",
        "    print(\"All the files are downloaded\")\n",
        "    download(Data_link, 'data.zip')\n",
        "\n",
        "    # extract the data \n",
        "    !unzip \"data.zip\"\n",
        "    !unrar x \"/content/drive/My Drive/my_data9.rar\"\n",
        "    \n",
        "\n",
        "# mountain drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "download_unzip_data()\n",
        "\n",
        "# test \n",
        "obj = MyCustomCallback()\n",
        "obj.on_epoch_end(1)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIRYG3r-DkUy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preprocessing \n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "def edit_path(img_path):\n",
        "    \"\"\"\n",
        "    this function do no't give shit about img type \n",
        "    \"\"\"\n",
        "    img_path = img_path.strip()\n",
        "    ls=img_path.split('/')\n",
        "    \n",
        "    if img_path[0]=='C':\n",
        "        ls = img_path.split('\\\\')\n",
        "      \n",
        "\n",
        "\n",
        "    if len(ls) ==2:\n",
        "        img_path = \"data/\" + img_path\n",
        "    elif len(ls) == 7:\n",
        "        if(img_path[0]=='C'):\n",
        "            img_path = 'my_data9'\n",
        "        else:\n",
        "            img_path = 'hard'\n",
        "        for i in range(5, len(ls), 1):\n",
        "            img_path = img_path +'/'+ ls[i]\n",
        "    else:\n",
        "      assert(\"un recognized type \")\n",
        "    #print(img_path)\n",
        "    return img_path\n",
        "\n",
        "def read_img(img_path):\n",
        "    \"\"\"\n",
        "    - train the model on RGB image,\n",
        "      as the simulator produce RGB image\n",
        "    \"\"\"\n",
        "    img_path = edit_path(img_path)\n",
        "    img = cv2.imread(img_path, -1)  # BGR\n",
        "    img = cv2.cvtColor(img , cv2.COLOR_BGR2RGB)  # RGB\n",
        "    return img\n",
        "\n",
        "def resize_img(img , tH=inputH , tW=inputW):\n",
        "    img = cv2.resize(img ,  (tW, tH))  # order of parameters, right  !??\n",
        "    return img\n",
        "\n",
        "def crop_img(img):\n",
        "    H , W , _ = img.shape\n",
        "    img = img[40:H-20, :, :]\n",
        "    return img\n",
        "\n",
        "def normalize_img_0_1(img):\n",
        "  img = img /255.0\n",
        "  img = img.astype(np.float32) # less memory\n",
        "  return img\n",
        "\n",
        "def preprocessing_pipeline(img):\n",
        "    img = normalize_img_0_1(img)\n",
        "    #img = resize_img(img) \n",
        "    img = crop_img(img)\n",
        "    return img\n",
        "\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9IwG4gKDwGJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Agumentation \n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "\n",
        "# angle \n",
        "\n",
        "def edit_angle(angle , camera):\n",
        "    angle = angle + angle_shift[camera]\n",
        "    return angle\n",
        "\n",
        "def flip_angle(angle):\n",
        "    # aid the horizontal_flip function\n",
        "    return - angle\n",
        "\n",
        "def h_angle_shift(angle, shifted_pixels):\n",
        "\n",
        "    shifted_angle = angle + shifted_pixels * H_angle_shift\n",
        "    if shifted_angle<-1:\n",
        "        shifted_angle=-1\n",
        "    elif shifted_angle >1:\n",
        "        shifted_angle=1\n",
        "    return shifted_angle\n",
        "\n",
        "# image\n",
        "\n",
        "def flip_img(img):\n",
        "    \"\"\"\n",
        "    :param img:  rgb , float [0 , 1]\n",
        "    \"\"\"\n",
        "    img = cv2.flip(img, 1) # horizontal\n",
        "    return img\n",
        "\n",
        "def darken(img , l_dark = 0.4 , h_dark = 0.75):\n",
        "    \"\"\"\n",
        "    - need image to be normalized [0 , 1] , why?!\n",
        "    \"\"\"\n",
        "    scaler = np.random.uniform(low=l_dark , high=h_dark)\n",
        "    img = img * scaler\n",
        "    return img\n",
        "\n",
        "# add noise \n",
        "def build_salt_peper_mat():\n",
        "    \"\"\"\n",
        "      pixels that have salt in it \n",
        "      will not have peper \n",
        "    \n",
        "      pixels that have peper in it \n",
        "      will not have slat \n",
        "    \n",
        "      so they will not affect each other \n",
        "    \"\"\"\n",
        "\n",
        "    peper_mat = np.ones(shape=[inputH, inputW, 1])  # multiply\n",
        "    salt_mat  = np.zeros(shape=[inputH, inputW, 1])  # add\n",
        "\n",
        "    for i in range(0 , inputH , 1):\n",
        "        for j in range(0 , inputW , 1):\n",
        "            rand = np.random.rand()\n",
        "            if rand <= Salt_Precentage:\n",
        "                salt_mat[i][j][0]=1\n",
        "            elif rand <= Peper_Precentage:\n",
        "                peper_mat[i][j][0]=0\n",
        "\n",
        "    return peper_mat, salt_mat\n",
        "\n",
        "def add_salt_peper_noise(img ,peper_mat, salt_mat):\n",
        "    # add peper\n",
        "    new_img= img * peper_mat\n",
        "    # add salt\n",
        "    new_img = new_img + salt_mat\n",
        "    # clip the value out from the boundries\n",
        "    new_img = np.clip(new_img , a_min=0 , a_max=1)\n",
        "    return new_img\n",
        "\n",
        "def add_shadows(img,l_shadow = 0.5, h_shadow = 0.85):\n",
        "    \"\"\"\n",
        "    :param img: have to be normalized [0 to 1]\n",
        "    - currently the shadows will cover all the V dimension,\n",
        "        but the H dim will be random\n",
        "    \"\"\"\n",
        "\n",
        "    \"\"\"\n",
        "    # image coordinates in open cv  (Y , X)\n",
        "    # indexing = (row , col , channels) , shape = (height , width , channels)\n",
        "    # functions take arguments in (col , row)   \n",
        "    #    _ _ _ _ _ _  (X)\n",
        "    #   |\n",
        "    #   |\n",
        "    #   |\n",
        "    #   |\n",
        "    #  (Y)\n",
        "    \"\"\"\n",
        "    \n",
        "    inputH , inputW , _ = img.shape\n",
        "    shadow_scaler = np.random.uniform(low=l_shadow , high=h_shadow)\n",
        "\n",
        "    # get the points\n",
        "    # upper part\n",
        "    # left\n",
        "    upper_left_Y  = 0\n",
        "    upper_left_X  = np.random.randint(low=0 , high=inputW//2)\n",
        "    # right\n",
        "    upper_right_Y = 0\n",
        "    upper_right_X = np.random.uniform(low=inputW//2+1 , high=inputW-1)\n",
        "\n",
        "    # lower part\n",
        "    # right\n",
        "    lower_right_Y = inputH-1\n",
        "    lower_right_X = np.random.uniform(low=inputW//2+1 , high=inputW-1)\n",
        "    # left\n",
        "    lower_left_Y = inputH-1\n",
        "    lower_left_X = np.random.uniform(low=0 , high=inputW//2)\n",
        "\n",
        "    # order of points matters as polyfill just c onnect the points (col , row)\n",
        "    points = [[upper_left_X, upper_left_Y],\n",
        "              [upper_right_X, upper_right_Y],\n",
        "              [lower_right_X, lower_right_Y],\n",
        "              [lower_left_X, lower_left_Y]]\n",
        "    mask = np.ones(img.shape)\n",
        "    cv2.fillPoly(mask, np.array([points], dtype=np.int32), [shadow_scaler, shadow_scaler, shadow_scaler])\n",
        "\n",
        "    img = img * mask\n",
        "    return img\n",
        "\n",
        "\n",
        "def h_shift_img(img , l_shift=H_shift_low , h_shift=H_shift_high):\n",
        "    h_shift_val = np.random.uniform(low=l_shift , high=h_shift)\n",
        "    v_shift_val = 0\n",
        "    hight , width  , _ = img.shape\n",
        "    Mat = np.array([[1 , 0 , h_shift_val],\n",
        "                    [0 , 1 , v_shift_val]] , dtype=np.float32)\n",
        "    img = cv2.warpAffine(img , Mat , dsize=(width , hight))\n",
        "    return img , h_shift_val\n",
        "    \n",
        "def vertical_shift(img, L_verticle_shift=-50, H_verticle_shift=-20):\n",
        "    assert (\"will have no use as we crop the image\")\n",
        "\n",
        "def agumentation_pipeline(img , original_angle , camera, apply_agum, peper_mat , salt_mat):\n",
        "    \"\"\"\n",
        "    :param img:  color: RGB, data_type: float range(0 , 1)\n",
        "    \"\"\"\n",
        "    images = []\n",
        "\n",
        "    # original image , calibrate the angle if needed\n",
        "    original_angle = edit_angle(original_angle , camera)\n",
        "    images.append((img , original_angle))\n",
        "\n",
        "    # case of validation data\n",
        "    if apply_agum==False:\n",
        "        return images\n",
        "\n",
        "    # darken the image\n",
        "    dark_img = darken(img)\n",
        "    images.append((dark_img , original_angle))\n",
        "\n",
        "    # add shadows\n",
        "    shadow_img = add_shadows(img)\n",
        "    images.append((shadow_img , original_angle))\n",
        "\n",
        "    # add noise \n",
        "    noisey_img = add_salt_peper_noise(img , peper_mat , salt_mat)\n",
        "    \n",
        "    \"\"\"\n",
        "    # flip image\n",
        "    # as the car is always in the right side of the rood \n",
        "    #but it may be good for avoiding overfitting \n",
        "    if camera=='center': \n",
        "      Hflip_angle = flip_angle(original_angle)\n",
        "      Hflip_img = flip_img(img)\n",
        "      images.append((Hflip_img, Hflip_angle))\n",
        "\n",
        "    # horizontal shift \n",
        "    shifted_img , shift_amount = h_shift_img(img)\n",
        "    new_angle = h_angle_shift(original_angle , shift_amount)\n",
        "    images.append((shifted_img , new_angle))\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    return images \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkwnR8pBEylB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading the Data \n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "\n",
        "def load_data(file_name , file_type):\n",
        "    if file_type=='data':\n",
        "        Data = pd.read_csv(file_name)\n",
        "    elif file_type=='hard':\n",
        "        Data = pd.read_csv(file_name, header=None)\n",
        "        Data.columns = ['center' , 'left' , 'right' , 'steering' , 'throttle' , 'brake' , 'speed']\n",
        "\n",
        "    print(\"size of data set is : \" , Data.shape)\n",
        "    data_set_length = Data.shape[0]\n",
        "\n",
        "    Left_camera = []\n",
        "    Center_camera = []\n",
        "    Right_camera = []\n",
        "    Angle = []\n",
        "    Throttle = []\n",
        "    Brake = []\n",
        "    Speed = []\n",
        "\n",
        "    for i in range(0 , data_set_length , 1):\n",
        "        angle = Data['steering'][i]\n",
        "        Left_camera.append(Data['left'][i])\n",
        "        Center_camera.append(Data['center'][i])\n",
        "        Right_camera.append(Data['right'][i])\n",
        "        Angle.append(Data['steering'][i])\n",
        "        Throttle.append(Data['throttle'][i])\n",
        "        Brake.append(Data['brake'][i])\n",
        "        Speed.append(Data['speed'][i])\n",
        "\n",
        "    Left_camera = np.array(Left_camera).reshape(-1 , 1)\n",
        "    Right_camera  = np.array(Right_camera).reshape(-1 , 1)\n",
        "    Center_camera = np.array(Center_camera).reshape(-1, 1)\n",
        "    Angle = np.array(Angle).reshape(-1 , 1)\n",
        "    Throttle = np.array(Throttle).reshape(-1 , 1)\n",
        "    Brake = np.array(Brake).reshape(-1 , 1)\n",
        "    Speed = np.array(Speed).reshape(-1 , 1)\n",
        "\n",
        "    return (Left_camera , Center_camera , Right_camera) , Angle, Speed\n",
        "\n",
        "def build_sequence(camera , angle , speed, time_steps):\n",
        "    \"\"\"\n",
        "    - Data order still been kept here.\n",
        "    build the input speed sequence\n",
        "    build the output speed corresponding to each sequence\n",
        "    \"\"\"\n",
        "\n",
        "    leftC , centerC , rightC = camera\n",
        "    \n",
        "    # discard the images and data with no complete sequence\n",
        "    leftC   = leftC[time_steps:]\n",
        "    centerC = centerC[time_steps:]\n",
        "    rightC  = rightC[time_steps:]\n",
        "    angle = angle[time_steps:]\n",
        "\n",
        "    # sample the speed\n",
        "    for i in range(0, speed.shape[0], 1):\n",
        "        speed[i] = sample_speed(speed[i])\n",
        "    # plot the speed distribution \n",
        "    \n",
        "    plt.hist(speed, bins = 30)  \n",
        "    plt.xlabel(\"speed value\")\n",
        "    plt.ylabel(\"frequency\")\n",
        "    plt.title(\"speed analysis\")\n",
        "    plt.show()\n",
        "\n",
        "    data_set_length = speed.shape[0] - time_steps\n",
        "    input_speed  = np.zeros(shape=[data_set_length, time_steps , 1]) # standard input for LSTM\n",
        "    Y_speed = np.zeros(shape=[data_set_length , 1])\n",
        "\n",
        "    for i in range(time_steps, speed.shape[0]):\n",
        "        # i is the Y value for the lstm\n",
        "        # i - time steps is the beginning of the sequence\n",
        "\n",
        "        # build the input\n",
        "        sequence = speed[i-time_steps:i]\n",
        "        input_speed[i-time_steps, : , :] = sequence\n",
        "        Y_speed[i-time_steps] = speed[i]\n",
        "\n",
        "    return (leftC , centerC ,rightC) , angle , input_speed , Y_speed\n",
        "\n",
        "\n",
        "def shuffle(camera, angle,  input_speed, Y_speed):\n",
        "    \"\"\"\n",
        "    shuffle sequences of the data\n",
        "    \"\"\"\n",
        "    np.random.seed(1) # keep same order for each shuffle to aid the model in non continuous training \n",
        "\n",
        "    index = np.random.permutation(angle.shape[0])\n",
        "    leftC , centerC , rightC = camera\n",
        "\n",
        "    # inputs\n",
        "    leftC = leftC[index]\n",
        "    centerC = centerC[index]\n",
        "    rightC = rightC[index]\n",
        "    input_speed = input_speed[index]\n",
        "\n",
        "    # outputs\n",
        "    angle = angle[index]\n",
        "    Y_speed = Y_speed[index]\n",
        "\n",
        "    #print(\"shuffling is done\")\n",
        "    return (leftC , centerC , rightC) , angle , input_speed , Y_speed\n",
        "\n",
        "\n",
        "def sample_speed(speed):\n",
        "    sp = speed\n",
        "    if sp >=5 and sp<=10:\n",
        "        sp = 10\n",
        "    elif sp >10 and sp <22:\n",
        "        sp = 15\n",
        "    # else leave it as it's \n",
        "    speed = sp\n",
        "    return speed\n",
        "\n",
        "def get_loss_weights(angle):\n",
        "    \"\"\"\n",
        "    - Data with straight forward angle will have small loss as it appear a lot in\n",
        "      the data set !!! , is there any other reason ????\n",
        "      does the sum of the losses for the different functions have to be summed to 1 !?\n",
        "    \"\"\"\n",
        "    assert(\"not implemented yet\")\n",
        "\n",
        "def generate_batch(camera, angle, input_speed, Y_speed, apply_agum , img_type , batch_size):\n",
        "    \"\"\"\n",
        "        my own generators , will be passed to fit_generator\n",
        "        to handle data sets with big size\n",
        "        drawback: if the data set size % batch size !=0\n",
        "        the model will bring data from the beginning of the data set (been processed twice )\n",
        "    \"\"\"\n",
        "\n",
        "    data_set_length = angle.shape[0]\n",
        "    leftC , centerC , rightC = camera\n",
        "    in_speed_batch  = []  \n",
        "    out_speed_batch = [] \n",
        "    out_angle_batch = [] \n",
        "    in_image_batch  = []\n",
        "    \n",
        "    peper_mat , salt_mat = build_salt_peper_mat()\n",
        "\n",
        "    index = 0\n",
        "    while True:\n",
        "        \n",
        "        original_angle = angle[index][0]\n",
        "\n",
        "        # don't change with the agumentation I do.\n",
        "        speed_sequence = input_speed[index]    #  ********************  bug *************************\n",
        "        current_speed = Y_speed[index][0]\n",
        "        \n",
        "        # normalizing \n",
        "        speed_sequence = speed_sequence  / 30.19\n",
        "        current_speed = current_speed  / 30.19\n",
        "\n",
        "        cams = 0\n",
        "        came = 3\n",
        "        if img_type == 'valid':  # just get the center \n",
        "            cams = 1\n",
        "            came = 2\n",
        "        ###### bug was in assigning the type of the camera  center and left and I guess this illustrate why it go more to right ######\n",
        "        for cam in range(cams , came):\n",
        "            camera = \"\"\n",
        "            if cam==0: # left\n",
        "                image_path  = leftC[index][0]\n",
        "                camera='left'\n",
        "            elif cam==1: # center\n",
        "                image_path  = centerC[index][0]\n",
        "                camera = 'center'\n",
        "            else: # right\n",
        "                image_path  = rightC[index][0]\n",
        "                camera = 'right'\n",
        "            \n",
        "            img = read_img(image_path)\n",
        "            img = preprocessing_pipeline(img)\n",
        "            images = agumentation_pipeline (img , original_angle, camera, apply_agum, peper_mat , salt_mat)\n",
        "            \n",
        "            for img , new_angle in images:\n",
        "                in_image_batch.append(img)\n",
        "                out_angle_batch.append(new_angle)\n",
        "                \n",
        "                in_speed_batch.append(speed_sequence)\n",
        "                out_speed_batch.append(current_speed)\n",
        "\n",
        "        index = (index +1)  % angle.shape[0]\n",
        "        if len(in_image_batch) >= batch_size:\n",
        "            # get new noise matrices as this will increase the randomness\n",
        "            peper_mat , salt_mat = build_salt_peper_mat()\n",
        "\n",
        "            # reshape \n",
        "            __in_image_batch  =  np.array(in_image_batch).reshape(-1 , inputH, inputW , 3)\n",
        "            __in_speed_batch  =  np.array(in_speed_batch).reshape(-1, Time_steps, 1)\n",
        "            __out_angle_bacth =  np.array(out_angle_batch).reshape(-1 , 1)\n",
        "            __out_speed_batch =  np.array(out_speed_batch).reshape(-1 , 1)\n",
        "\n",
        "            in_image_batch  = []\n",
        "            in_speed_batch  = []\n",
        "            out_angle_batch = []\n",
        "            out_speed_batch = []\n",
        "\n",
        "            inputs =[__in_image_batch , __in_speed_batch]\n",
        "            outputs = [__out_angle_bacth , __out_speed_batch]\n",
        "            #print(\"batch size   \" , __in_image_batch.shape[0])\n",
        "            yield (inputs, outputs)\n",
        "    return\n",
        "\n",
        "def get_data(file_name , file_type):\n",
        "    camera, angle, speed = load_data(file_name , file_type)\n",
        "    camera, angle, input_speed, Y_speed = build_sequence(camera, angle, speed, Time_steps)\n",
        "    #camera, angle, input_speed, Y_speed = shuffle(camera, angle, input_speed, Y_speed)\n",
        "    return camera, angle, input_speed,Y_speed\n",
        "\n",
        "def conc(X ,Y):\n",
        "    X = np.row_stack((X , Y))\n",
        "    return X\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mv3392HMFChR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Dense , LSTM , concatenate , Input\n",
        "from keras.layers import  Conv2D , MaxPool2D , Flatten , ZeroPadding2D\n",
        "from keras.optimizers import SGD , Adam\n",
        "from keras.utils import plot_model\n",
        "from keras import Model\n",
        "from keras.initializers import glorot_uniform, he_uniform\n",
        "from keras.layers import BatchNormalization, Activation\n",
        "from keras.regularizers import l2\n",
        "from keras.layers import Dropout\n",
        "import math\n",
        "\n",
        "\n",
        "def get_speed_out(speed_input , shared_layer):\n",
        "    \n",
        "    init = glorot_uniform()\n",
        "    LSTM_layer = LSTM(128, activation='tanh', return_sequences=False, init = init)(speed_input)\n",
        "    \n",
        "    FC_layer = Dense(50, activation='relu' , init = init, kernel_regularizer = l2(FC_reg_val))(LSTM_layer)\n",
        "\n",
        "    FC_layer = Dense(50, activation='relu' , init = init, kernel_regularizer = l2(FC_reg_val))(FC_layer)\n",
        "\n",
        "    # concatenate the input from the shared layer\n",
        "    merged_input = concatenate(inputs=[FC_layer , shared_layer])\n",
        "\n",
        "    FC_layer = Dense(50 , activation='relu' , init = init,  kernel_regularizer = l2(FC_reg_val))(merged_input)\n",
        "    \n",
        "    # *************** regression layer ******************\n",
        "    speed_out = Dense(1 , name='speed_out', init = init,   kernel_regularizer = l2(FC_reg_val))(FC_layer)\n",
        "\n",
        "    return speed_out\n",
        "\n",
        "def Multi_task_Multi_output_Model(inputH, inputW, inputC, time_steps):\n",
        "    init = glorot_uniform()\n",
        "  \n",
        "    image_input = Input(shape=(inputH ,inputW , inputC))\n",
        "    speed_input = Input(shape=(time_steps,1))\n",
        "\n",
        "    # CNN layers\n",
        "    # first layer\n",
        "    padded_img = ZeroPadding2D((2 , 2))(image_input)\n",
        "    CNN_layer = Conv2D(96, (11 , 11),strides=[2 , 2],\n",
        "                       init = init, name='cnn1')(padded_img)\n",
        "    batch_norm_layer = BatchNormalization()(CNN_layer)  \n",
        "    activ_layer = Activation('relu')(batch_norm_layer)\n",
        "    max_pool = MaxPool2D((3 , 3),strides=[2 , 2])(activ_layer)\n",
        "    \n",
        "  \n",
        "    # second layer\n",
        "    CNN_layer = Conv2D(256 , (5 , 5), padding='same',\n",
        "                       init = init, name='cnn2')(max_pool)\n",
        "    batch_norm_layer = BatchNormalization()(CNN_layer) \n",
        "    activ_layer = Activation('relu')(batch_norm_layer)\n",
        "    max_pool = MaxPool2D((3 , 3) , strides=[2 , 2])(activ_layer)\n",
        "\n",
        "    # third layer\n",
        "    CNN_layer = Conv2D(384, (3 , 3), strides=[2, 2],\n",
        "                       init = init, name='cnn3')(max_pool) \n",
        "    activ_layer = Activation('relu')(CNN_layer)                   \n",
        "\n",
        "    # forth layer\n",
        "    CNN_layer = Conv2D(384, (3 , 3), padding='same',\n",
        "                       init = init, name='cnn4')(activ_layer) \n",
        "    activ_layer = Activation('relu')(CNN_layer)\n",
        "\n",
        "    # fifth layer\n",
        "    CNN_layer = Conv2D(256, (3 , 3),\n",
        "                       init= init, name='cnn5')(activ_layer) \n",
        "    activ_layer = Activation('relu')(CNN_layer)\n",
        "\n",
        "    # fully connected layers\n",
        "    Flatten_layer = Flatten()(activ_layer)\n",
        "\n",
        "    # FC1\n",
        "    FC_layer = Dense(1024, activation='relu' , init = init ,kernel_regularizer = l2(FC_reg_val), name='anglefc1')(Flatten_layer) \n",
        "    \n",
        "    # FC2 and shared layer between the 2 models\n",
        "    shared_layer = Dense(50, activation='relu' , init = init,kernel_regularizer = l2(FC_reg_val), name='anglefc2')(FC_layer)\n",
        "\n",
        "    ################################################\n",
        "    # send it to the speed model to be concatenated\n",
        "    speed_out = get_speed_out(speed_input, shared_layer)\n",
        "    ################################################\n",
        "    \n",
        "    \n",
        "    # FC3\n",
        "    FC_layer = Dense(50, activation='relu' , init = init,kernel_regularizer = l2(FC_reg_val), name='anglefc3')(shared_layer)\n",
        "\n",
        "    # steering angle prediction it's regression (continuous) value\n",
        "    angle_out = Dense(1 , name='angle_out', init = init, kernel_regularizer = l2(FC_reg_val))(FC_layer)\n",
        "    #############################################################\n",
        "  \n",
        "    model = Model(inputs=[image_input , speed_input] , outputs=[angle_out , speed_out])\n",
        "    opt = Adam(lr = Learning_rate)\n",
        "    model.compile(optimizer=opt , loss=['mse', 'mse'], loss_weights=[1, 1])\n",
        "    plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
        "    return model\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31ILnu8MFLg2",
        "colab_type": "code",
        "outputId": "d8259617-35d6-495c-d269-e67ee3d5813a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 876
        }
      },
      "source": [
        " # training\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models  import load_model\n",
        "from keras.callbacks import LambdaCallback\n",
        "\n",
        "def train_model():\n",
        "    model = Multi_task_Multi_output_Model(inputH, inputW, inputC, Time_steps)\n",
        "\n",
        "    # Data \n",
        "    T_camera, T_angle, T_input_speed,T_Y_speed = get_data(Train_file_name , 'hard')\n",
        "\n",
        "    # unpack\n",
        "    T_leftC, T_centerC, T_rightC = T_camera\n",
        "    \n",
        "    # split\n",
        "    T_leftC , V_leftC , T_centerC , V_centerC , T_rightC , V_rightC , T_angle , V_angle \\\n",
        "    , T_input_speed , V_input_speed, T_Y_speed , V_Y_speed = train_test_split(T_leftC , T_centerC , T_rightC , T_angle \\\n",
        "                                                                              , T_input_speed , T_Y_speed , test_size = Spliting_precentage , random_state=2)\n",
        "    # pack \n",
        "    T_camera = (T_leftC, T_centerC, T_rightC)\n",
        "    V_camera = (V_leftC, V_centerC, V_rightC)\n",
        "\n",
        "    T_steps_per_epoch = math.ceil( (T_angle.shape[0] * Aug_out)/ Batch_size)\n",
        "    V_steps_per_epoch = math.ceil(V_angle.shape[0]  / Batch_size)\n",
        "\n",
        "    print(\"train angle \", T_angle.shape)\n",
        "    print(\"train input speed \", T_input_speed.shape)\n",
        "\n",
        "    print(\"validation angle \", V_angle.shape)\n",
        "    print(\"validation input speed \",V_input_speed.shape)\n",
        "\n",
        "    train_generator = generate_batch(T_camera , T_angle , T_input_speed , T_Y_speed , True , 'train' ,  Batch_size)\n",
        "    valid_generator = generate_batch(V_camera , V_angle , V_input_speed , V_Y_speed , False , 'valid' ,  Batch_size)\n",
        "\n",
        "    #test_model_feed(valid_generator)\n",
        "\n",
        "    best_model = ModelCheckpoint('BMulti_model.h5', monitor='val_loss' , save_best_only=True)\n",
        "    frequent_model = ModelCheckpoint('FMulti_model.h5', monitor='val_loss' , save_best_only=False)\n",
        "    frequent_weights = ModelCheckpoint('BMulti_model_weights.h5', monitor='val_loss' , save_weights_only=True, save_best_only=True)\n",
        "\n",
        "    model.fit_generator(train_generator,\n",
        "                        steps_per_epoch = T_steps_per_epoch,\n",
        "                        validation_data = valid_generator,\n",
        "                        validation_steps = V_steps_per_epoch,\n",
        "                        verbose = 1,\n",
        "                        epochs=Num_epochs,\n",
        "                        callbacks = [best_model , frequent_model, frequent_weights, MyCustomCallback()])\n",
        "    \n",
        "    # plot the results \n",
        "    visualize_training_history(history.history)\n",
        "    save_file(history.history, 'history.pickle')\n",
        "\n",
        "    model.save_weights(\"final_multi_model_weights.h5\")\n",
        "    model.save(Model_name)\n",
        "\n",
        "print(\"start\")\n",
        "train_model()\n",
        "print(\"end\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "start\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:42: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(96, (11, 11), strides=[2, 2], name=\"cnn1\", kernel_initializer=<keras.ini...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (5, 5), padding=\"same\", name=\"cnn2\", kernel_initializer=<keras.ini...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:57: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(384, (3, 3), strides=[2, 2], name=\"cnn3\", kernel_initializer=<keras.ini...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:62: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(384, (3, 3), padding=\"same\", name=\"cnn4\", kernel_initializer=<keras.ini...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:67: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"cnn5\", kernel_initializer=<keras.ini...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:74: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1024, activation=\"relu\", kernel_regularizer=<keras.reg..., name=\"anglefc1\", kernel_initializer=<keras.ini...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:77: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(50, activation=\"relu\", kernel_regularizer=<keras.reg..., name=\"anglefc2\", kernel_initializer=<keras.ini...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(128, activation=\"tanh\", return_sequences=False, kernel_initializer=<keras.ini...)`\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(50, activation=\"relu\", kernel_regularizer=<keras.reg..., kernel_initializer=<keras.ini...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(50, activation=\"relu\", kernel_regularizer=<keras.reg..., kernel_initializer=<keras.ini...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(50, activation=\"relu\", kernel_regularizer=<keras.reg..., kernel_initializer=<keras.ini...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, name=\"speed_out\", kernel_regularizer=<keras.reg..., kernel_initializer=<keras.ini...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:86: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(50, activation=\"relu\", kernel_regularizer=<keras.reg..., name=\"anglefc3\", kernel_initializer=<keras.ini...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:89: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, name=\"angle_out\", kernel_regularizer=<keras.reg..., kernel_initializer=<keras.ini...)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "size of data set is :  (78943, 7)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEWCAYAAACnlKo3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAee0lEQVR4nO3de5ReVZ3m8e8D4SYCCVJmAUGDEi80KkKEeFmOIxoCqGFsRFAhMjRRARvHcWnUmUZBZqG22jBtx8EmkqgYEaTJIBhjwFF7GUhxCzfpFDeTGJJggHBRFHjmj7NLj5WqypuTvFV5q57PWu96z/ntfc7Zmxfqx97nJttEREQ0sd1wNyAiIjpXkkhERDSWJBIREY0liURERGNJIhER0ViSSERENJYkEtFGkh6Q9LZhOK4lHbAF279I0hOStt+a7YqRZ8xwNyAitj22fwM8f7jbEdu+jEQiIqKxJJEYsSR9StIqSY9LukfSESX+OUmXS/p+KbtZ0mtq2+0j6QpJ6yTdL+nva2XbSZol6V5Jv5N0maQ9a+UnSXqwlH12E+07RtItkjZIWiHpc7WyiWVKaoak30h6uL4/SYdJ+pWkRyWtlvTPknbs5xivk7SmPi0l6d2Sbqvtp7u0YY2kr/Y5/piy/kFJ95V/XvdLev9m/RgxYiWJxIgk6eXAmcDrbO8GHAk8UKsyHfgBsCdwKfBvknaQtB3wf4HbgH2BI4CPSTqybPdR4FjgPwH7AI8AXy/HPBCYDZxUyl4ATBikmU8CJwNjgWOAj0g6tk+dNwEvL+34B0mvLPFngf8G7AW8vpSf3vcAtpcCvwOm1sInAfPK8gXABbZ3B14KXNZ3H5J2BS4Ejir/LN8A3DpIv2IUSRKJkepZYCfgQEk72H7A9r218ptsX277T8BXgZ2BKcDrgC7b59j+o+37gG8CJ5TtPgx81vZK208DnwOOK//Hfhxwte2fl7L/CTw3UANt/8z27bafs70M+B5Vcqr7vO3f276NKrG9pmx7k+0ltp+x/QDwf/rZttdc4AMAZdR0JFXiBPgTcICkvWw/YXvJAPt4DjhI0i62V9u+c6B+xeiSJBIjku0e4GNUf+TXSpovaZ9alRW1us8BK6lGDy8G9inTRI9KehT4DDC+VH8xcGWt7G6qhDW+bF/f75NUo4B+STpc0vVl2uwxqgS1V59qD9WWn6Kc7Jb0MklXS3pI0gbgf/Wzba/vAO8sI4rjgV/YXl3KTgVeBvxa0lJJ7+i7cenHe0v7Vkv6kaRXDNSvGF2SRGLEsn2p7TdR/eE38MVa8X69C2UKawLwW6okcL/tsbXPbraPLtVXUE3r1Mt3tr0KWN1nv8+jmtIayKXAAmA/23sA3wDUYvdmA78GJpWpqM8MtG1p26+Ad1NNZX27Vrbc9onAC6n++Vxekk3ffSy0/XZg73Lcb7bYzhjhkkRiRJL0cklvlbQT8Afg9/z11NKh5QTzGKoRy9PAEuBG4PFyUn4XSdtLOkjS68p23wDOk/TicpwuSdNL2eXAOyS9qZzkPofB/xvbDVhv+w+SDgPetxld3A3YADxRRgUf2UT9ecAngVcBP+wNSvqApK4yGnu0hP9qCk7SeEnTS3J5Gniib50YvZJEYqTaCTgfeJhqSuiFwKdr5VdRTdE8QvV/5++2/SfbzwLvAA4G7i/b/yuwR9nuAqrRw08kPU6VeA4HKOcJzqAaYawu+145SBtPB84p+/kH+jmpPYhPUCWdx6lGBd/fRP0rKVNxtp+qxacBd0p6ovTtBNu/77PtdsDHqUZq66nOvWwqacUoobyUKkabcintAbY/MNxtGUqS7gU+ZPunw92WGDkyEokYBST9LdV5oeuGuy0xsuSxJxEjnKSfAQcCJ5VzHxFbTaazIiKisUxnRUREY6NuOmuvvfbyxIkTh7sZEREd46abbnrYdld/ZaMuiUycOJHu7u7hbkZERMeQ9OBAZZnOioiIxpJEIiKisSSRiIhoLEkkIiIaSxKJiIjGkkQiIqKxJJGIiGgsSSQiIhpLEomIiMZG3R3rEUNt4qwftVTvgfOPaXNLIra+jEQiIqKxJJGIiGgsSSQiIhpLEomIiMaSRCIiorEkkYiIaKxtSUTSyyXdWvtskPQxSXtKWiRpefkeV+pL0oWSeiQtk3RIbV8zSv3lkmbU4odKur1sc6Ektas/ERGxsbYlEdv32D7Y9sHAocBTwJXALGCx7UnA4rIOcBQwqXxmArMBJO0JnA0cDhwGnN2beEqd02rbTWtXfyIiYmNDNZ11BHCv7QeB6cDcEp8LHFuWpwPzXFkCjJW0N3AksMj2etuPAIuAaaVsd9tLbBuYV9tXREQMgaFKIicA3yvL422vLssPAePL8r7Aito2K0tssPjKfuIbkTRTUrek7nXr1m1JPyIioqbtSUTSjsC7gB/0LSsjCLe7DbYvsj3Z9uSurq52Hy4iYtQYipHIUcDNtteU9TVlKoryvbbEVwH71babUGKDxSf0E4+IiCEyFEnkRP4ylQWwAOi9wmoGcFUtfnK5SmsK8FiZ9loITJU0rpxQnwosLGUbJE0pV2WdXNtXREQMgbY+xVfSrsDbgQ/VwucDl0k6FXgQOL7ErwGOBnqoruQ6BcD2eknnAktLvXNsry/LpwOXALsA15ZPREQMkbYmEdtPAi/oE/sd1dVafesaOGOA/cwB5vQT7wYO2iqNjYiIzZY71iMiorEkkYiIaCxJJCIiGksSiYiIxpJEIiKisSSRiIhoLEkkIiIaSxKJiIjGkkQiIqKxJJGIiGgsSSQiIhpLEomIiMaSRCIiorEkkYiIaCxJJCIiGksSiYiIxpJEIiKisSSRiIhoLEkkIiIaa2sSkTRW0uWSfi3pbkmvl7SnpEWSlpfvcaWuJF0oqUfSMkmH1PYzo9RfLmlGLX6opNvLNhdKUjv7ExERf63dI5ELgB/bfgXwGuBuYBaw2PYkYHFZBzgKmFQ+M4HZAJL2BM4GDgcOA87uTTylzmm17aa1uT8REVHTtiQiaQ/gzcDFALb/aPtRYDowt1SbCxxblqcD81xZAoyVtDdwJLDI9nrbjwCLgGmlbHfbS2wbmFfbV0REDIF2jkT2B9YB35J0i6R/lbQrMN726lLnIWB8Wd4XWFHbfmWJDRZf2U98I5JmSuqW1L1u3bot7FZERPRqZxIZAxwCzLb9WuBJ/jJ1BUAZQbiNbeg9zkW2J9ue3NXV1e7DRUSMGu1MIiuBlbZvKOuXUyWVNWUqivK9tpSvAvarbT+hxAaLT+gnHhERQ6RtScT2Q8AKSS8voSOAu4AFQO8VVjOAq8ryAuDkcpXWFOCxMu21EJgqaVw5oT4VWFjKNkiaUq7KOrm2r4iIGAJj2rz/jwLflbQjcB9wClXiukzSqcCDwPGl7jXA0UAP8FSpi+31ks4FlpZ659heX5ZPBy4BdgGuLZ+IiBgibU0itm8FJvdTdEQ/dQ2cMcB+5gBz+ol3AwdtYTMjIqKh3LEeERGNJYlERERjSSIREdFYkkhERDSWJBIREY0liURERGNJIhER0ViSSERENJYkEhERjSWJREREY0kiERHRWJJIREQ0liQSERGNJYlERERjSSIREdFYkkhERDSWJBIREY0liURERGNJIhER0Vhbk4ikByTdLulWSd0ltqekRZKWl+9xJS5JF0rqkbRM0iG1/cwo9ZdLmlGLH1r231O2VTv7ExERf20oRiL/2fbBtieX9VnAYtuTgMVlHeAoYFL5zARmQ5V0gLOBw4HDgLN7E0+pc1ptu2nt705ERPQajums6cDcsjwXOLYWn+fKEmCspL2BI4FFttfbfgRYBEwrZbvbXmLbwLzaviIiYgi0O4kY+ImkmyTNLLHxtleX5YeA8WV5X2BFbduVJTZYfGU/8Y1ImimpW1L3unXrtqQ/ERFRM6bN+3+T7VWSXggskvTreqFtS3Kb24Dti4CLACZPntz240VEjBZtHYnYXlW+1wJXUp3TWFOmoijfa0v1VcB+tc0nlNhg8Qn9xCMiYoi0LYlI2lXSbr3LwFTgDmAB0HuF1QzgqrK8ADi5XKU1BXisTHstBKZKGldOqE8FFpayDZKmlKuyTq7tKyIihkA7p7PGA1eWq27HAJfa/rGkpcBlkk4FHgSOL/WvAY4GeoCngFMAbK+XdC6wtNQ7x/b6snw6cAmwC3Bt+URExBBpWxKxfR/wmn7ivwOO6Cdu4IwB9jUHmNNPvBs4aIsbGxERjeSO9YiIaCxJJCIiGksSiYiIxpJEIiKisU0mkXK3+Rm151VFREQArY1E3gvsAyyVNF/SkXlabkREQAtJxHaP7c8CLwMupbrU9kFJny9P2I2IiFGqpXMikl4NfAX4MnAF8B5gA3Bd+5oWERHbuk3ebCjpJuBR4GJglu2nS9ENkt7YzsZFRMS2rZU71t9T7j7fiO13b+X2REREB2llOuvvJI3tXSkPQvxCG9sUEREdopUkcpTtR3tXytsFj25fkyIiolO0kkS2l7RT74qkXYCdBqkfERGjRCvnRL4LLJb0rbJ+Cn95R3pERIxim0witr8oaRl/eXz7ubYXtrdZERHRCVp6n4jtvPApIiI20sqzs94tabmkxyRtkPS4pA1D0biIiNi2tTIS+RLwTtt3t7sxERHRWVq5OmtNEkhERPSnlSTSLen7kk4sU1vvltTyneqStpd0i6Sry/r+km6Q1FP2u2OJ71TWe0r5xNo+Pl3i90g6shafVmI9kma13OuIiNgqWkkiuwNPAVOBd5bPOzbjGGcB9ZHMF4Gv2T4AeAQ4tcRPBR4p8a+Vekg6EDgB+BtgGvAvJTFtD3wdOAo4EDix1I2IiCHSyiW+pzTduaQJwDHAecDHy3tI3gq8r1SZC3wOmA1ML8sAlwP/XOpPB+aXBz/eL6kHOKzU6+l9rpek+aXuXU3bGxERm6eVq7NeJmmxpDvK+qsl/Y8W9/9PwCeB58r6C4BHbT9T1lcC+5blfYEVAKX8sVL/z/E+2wwU768PMyV1S+pet25di02PiIhNaWU665vAp4E/AdheRjW9NChJ7wDW2r5pi1q4Fdi+yPZk25O7urqGuzkRESNGK5f4Ps/2jX3eiPvMQJVr3gi8S9LRwM5U51YuAMZKGlNGGxOAVaX+KmA/YKWkMcAewO9q8V71bQaKR0TEEGhlJPKwpJcCBpB0HLB6UxvZ/rTtCbYnUo1crrP9fuB64LhSbQZwVVleUNYp5dfZdomfUK7e2h+YBNwILAUmlau9dizHWNBCfyIiYitpZSRyBnAR8ApJq4D7gQ9swTE/Bcwv7yS5heqNiZTvb5cT5+spU2a275R0GdUJ82eAM2w/CyDpTGAhsD0wx/adW9CuiIjYTK1cnXUf8DZJuwLb2X58cw9i+2fAz2r7O6yfOn+gend7f9ufR3WFV9/4NcA1m9ueiIjYOlp5x/o/9FkHwPY5bWpTRER0iFams56sLe9MdaNhHoMSEREtTWd9pb4u6R+pzkNERMQo18rVWX09j+py2oiIGOVaOSdyO+XyXqqroLqAnA+JiIiWzonUH7b4DNWj4Vu52TAiIka4VpJI30t6d6/fvW57/VZtUUREdIxWksjNVI8XeQQQMBb4TSkz8JL2NC0iIrZ1rZxYX0T1ety9bL+AanrrJ7b3t50EEhExirWSRKaUO8MBsH0t8Ib2NSkiIjpFK9NZvy3vD/lOWX8/8Nv2NSkiIjpFKyORE6ku670S+GFZPrGdjYqIiM7Qyh3r64GzJO1q+8lN1Y+IiNGjldfjvkHSXZTnZUl6jaR/aXvLIiJim9fKdNbXgCOp3jKI7duAN7ezURER0RlaenaW7RV9Qs+2oS0REdFhWrk6a4WkNwCWtANwFnkUfERE0NpI5MNUr8jdF1gFHFzWIyJilBt0JCJpe+AC2+8fovZEREQHGXQkYvtZ4MWSdtzcHUvaWdKNkm6TdKekz5f4/pJukNQj6fu9+5a0U1nvKeUTa/v6dInfI+nIWnxaifVImrW5bYyIiC3TyjmR+4B/l7SA2qtybX91E9s9DbzV9hPlXMovJV0LfBz4mu35kr4BnArMLt+P2D5A0gnAF4H3SjoQOAH4G2Af4KeSXlaO8XXg7cBKYKmkBbbvaq3rERGxpQYciUj6dll8F3B1qbtb7TMoV54oqzuUj4G3ApeX+Fzg2LI8vaxTyo9Q9cz56cB820/bvh/oAQ4rnx7b99n+IzC/1I2IiCEy2EjkUEn7UD32/X832Xk5p3ITcADVqOFe4NHaS61WUp2wp3yvALD9jKTHgBeU+JLabuvbrOgTP7xJOyMiopnBksg3gMXA/kB3LS5afI9IOadysKSxVM/eekXzpjYnaSYwE+BFL3rRcDQhImJEGnA6y/aFtl8JfMv2S2qfzX6PiO1HgeuB1wNjJfUmrwlUlw1TvvcDKOV7UN0l/+d4n20Givd3/ItsT7Y9uaura3OaHhERg9jkfSK2P9Jkx5K6yggESbtQnQC/myqZHFeqzQCuKssLyjql/DrbLvETytVb+wOTgBuBpcCkcrXXjlQn3xc0aWtERDTTytVZTe0NzC3nRbYDLrN9dXmY43xJXwBuAS4u9S8Gvi2pB1hPlRSwfaeky4C7gGeAM8o0GZLOBBYC2wNzbN/Zxv5EREQfbUsitpcBr+0nfh/VlVV9438A3jPAvs4Dzusnfg1wzcZbRETEUGjpAYwRERH9SRKJiIjGkkQiIqKxJJGIiGgsSSQiIhpLEomIiMaSRCIiorEkkYiIaCxJJCIiGksSiYiIxpJEIiKisSSRiIhoLEkkIiIaSxKJiIjGkkQiIqKxJJGIiGgsSSQiIhpLEomIiMaSRCIiorG2JRFJ+0m6XtJdku6UdFaJ7ylpkaTl5XtciUvShZJ6JC2TdEhtXzNK/eWSZtTih0q6vWxzoSS1qz8REbGxdo5EngH+u+0DgSnAGZIOBGYBi21PAhaXdYCjgEnlMxOYDVXSAc4GDgcOA87uTTylzmm17aa1sT8REdFH25KI7dW2by7LjwN3A/sC04G5pdpc4NiyPB2Y58oSYKykvYEjgUW219t+BFgETCtlu9teYtvAvNq+IiJiCAzJORFJE4HXAjcA422vLkUPAePL8r7AitpmK0tssPjKfuIRETFE2p5EJD0fuAL4mO0N9bIygvAQtGGmpG5J3evWrWv34SIiRo22JhFJO1AlkO/a/mEJrylTUZTvtSW+CtivtvmEEhssPqGf+EZsX2R7su3JXV1dW9apiIj4s3ZenSXgYuBu21+tFS0Aeq+wmgFcVYufXK7SmgI8Vqa9FgJTJY0rJ9SnAgtL2QZJU8qxTq7tKyIihsCYNu77jcBJwO2Sbi2xzwDnA5dJOhV4EDi+lF0DHA30AE8BpwDYXi/pXGBpqXeO7fVl+XTgEmAX4NryiYiIIdK2JGL7l8BA920c0U99A2cMsK85wJx+4t3AQVvQzIiI2AK5Yz0iIhpLEomIiMaSRCIiorEkkYiIaCxJJCIiGksSiYiIxpJEIiKisSSRiIhoLEkkIiIaSxKJiIjGkkQiIqKxJJGIiGgsSSQiIhpLEomIiMaSRCIiorEkkYiIaCxJJCIiGksSiYiIxpJEIiKisSSRiIhorG1JRNIcSWsl3VGL7SlpkaTl5XtciUvShZJ6JC2TdEhtmxml/nJJM2rxQyXdXra5UJLa1ZeIiOhfO0cilwDT+sRmAYttTwIWl3WAo4BJ5TMTmA1V0gHOBg4HDgPO7k08pc5pte36HisiItqsbUnE9s+B9X3C04G5ZXkucGwtPs+VJcBYSXsDRwKLbK+3/QiwCJhWyna3vcS2gXm1fUVExBAZ6nMi422vLssPAePL8r7Ailq9lSU2WHxlP/F+SZopqVtS97p167asBxER8WfDdmK9jCA8RMe6yPZk25O7urqG4pAREaPCUCeRNWUqivK9tsRXAfvV6k0oscHiE/qJR0TEEBrqJLIA6L3CagZwVS1+crlKawrwWJn2WghMlTSunFCfCiwsZRskTSlXZZ1c21dERAyRMe3asaTvAW8B9pK0kuoqq/OByySdCjwIHF+qXwMcDfQATwGnANheL+lcYGmpd47t3pP1p1NdAbYLcG35RETEEGpbErF94gBFR/RT18AZA+xnDjCnn3g3cNCWtDEiIrZM7liPiIjGkkQiIqKxJJGIiGgsSSQiIhpLEomIiMaSRCIiorEkkYiIaCxJJCIiGksSiYiIxpJEIiKisSSRiIhoLEkkIiIaSxKJiIjGkkQiIqKxJJGIiGgsSSQiIhpr20upIrbExFk/aqneA+cf0+aWRMRgMhKJiIjGMhKJiG1eRqbbro4fiUiaJukeST2SZg13eyIiRpOOHolI2h74OvB2YCWwVNIC23cNb8siYjhkxDL0OjqJAIcBPbbvA5A0H5gOJIlEdIBW/+h3wnGHKzENd+KU7bbseChIOg6YZvvvyvpJwOG2z+xTbyYws6y+HLin4SH3Ah5uuO22ZKT0A0ZOX9KPbc9I6cvW6MeLbXf1V9DpI5GW2L4IuGhL9yOp2/bkrdCkYTVS+gEjpy/px7ZnpPSl3f3o9BPrq4D9ausTSiwiIoZApyeRpcAkSftL2hE4AVgwzG2KiBg1Ono6y/Yzks4EFgLbA3Ns39nGQ27xlNg2YqT0A0ZOX9KPbc9I6Utb+9HRJ9YjImJ4dfp0VkREDKMkkYiIaCxJpAUj6dEqkh6QdLukWyV1D3d7WiVpjqS1ku6oxfaUtEjS8vI9bjjb2KoB+vI5SavK73KrpKOHs42tkLSfpOsl3SXpTklnlXhH/S6D9KMTf5OdJd0o6bbSl8+X+P6Sbih/w75fLkTaOsfMOZHBlUer/Ae1R6sAJ3bqo1UkPQBMtt1RN1FJejPwBDDP9kEl9iVgve3zS3IfZ/tTw9nOVgzQl88BT9j+x+Fs2+aQtDewt+2bJe0G3AQcC3yQDvpdBunH8XTebyJgV9tPSNoB+CVwFvBx4Ie250v6BnCb7dlb45gZiWzanx+tYvuPQO+jVWII2f45sL5PeDowtyzPpfoPf5s3QF86ju3Vtm8uy48DdwP70mG/yyD96DiuPFFWdygfA28FLi/xrfqbJIls2r7Aitr6Sjr0X7DCwE8k3VQeB9PJxtteXZYfAsYPZ2O2gjMlLSvTXdv0FFBfkiYCrwVuoIN/lz79gA78TSRtL+lWYC2wCLgXeNT2M6XKVv0bliQy+rzJ9iHAUcAZZWql47mal+3kudnZwEuBg4HVwFeGtzmtk/R84ArgY7Y31Ms66Xfppx8d+ZvYftb2wVRP8DgMeEU7j5cksmkj6tEqtleV77XAlVT/knWqNWU+u3dee+0wt6cx22vKf/zPAd+kQ36XMu9+BfBd2z8s4Y77XfrrR6f+Jr1sPwpcD7weGCup9+byrfo3LElk00bMo1Uk7VpOHCJpV2AqcMfgW23TFgAzyvIM4KphbMsW6f2jW/wXOuB3KSdxLwbutv3VWlFH/S4D9aNDf5MuSWPL8i5UFwTdTZVMjivVtupvkquzWlAu7fsn/vJolfOGuUmNSHoJ1egDqkfeXNopfZH0PeAtVI+1XgOcDfwbcBnwIuBB4Hjb2/wJ6wH68haqaRMDDwAfqp1X2CZJehPwC+B24LkS/gzV+YSO+V0G6ceJdN5v8mqqE+fbUw0SLrN9Tvlvfz6wJ3AL8AHbT2+VYyaJREREU5nOioiIxpJEIiKisSSRiIhoLEkkIiIaSxKJiIjGkkQihpmkn0mavK3sJ2JzJIlERERjSSIRfZQ7+39U3slwh6T3lvgDkr5U3sdyo6QDSrxL0hWSlpbPG2v7mVPq3iJpeonvImm+pLslXQns0k8bpkn6QW39LZKuLsuzJXXX3xfRz/ZP1JaPk3TJYG2NaGrMpqtEjDrTgN/aPgZA0h61ssdsv0rSyVRPMXgHcAHwNdu/lPQiYCHwSuCzwHW2/2t5FMWNkn4KfAh4yvYryx3GN/fThp8CF0na1faTwHup7jgG+Kzt9eVdN4slvdr2shb7NlBbIxpJEonY2O3AVyR9Ebja9i9qZd+rfX+tLL8NOLB6BBMAu5cnwk4F3iXpEyW+M9WjQN4MXAhge5mkjRKA7Wck/Rh4p6TLgWOAT5bi48tj/McAewMHAq0mkX7bWnsHRcRmSRKJ6MP2f0g6BDga+IKkxbbP6S2uVy3f2wFTbP+hvp/yYL+/tX1Pn3irTZkPnEn1Aqtu249L2h/4BPA624+Uaaqd++tGbble3m9bI5rKOZGIPiTtQzXd9B3gy8AhteL31r5/VZZ/Any0tv3BZXEh8NGSTJD02hL/OfC+EjsIePUATfl/5din8ZeprN2BJ4HHJI2nei9Mf9ZIeqWk7aieQNtroLZGNJKRSMTGXgV8WdJzwJ+Aj9TKxpXpp6epnvIK8PfA10t8DFWS+DBwLtV5k2Xlj/n9VOdQZgPfknQ31WO6b+qvEbafLSfTP0h5tLrt2yTdAvya6o2b/z5AH2YBVwPrgG7g+Ztoa0QjeYpvRIskPQBMtv3wcLclYluR6ayIiGgsI5GIiGgsI5GIiGgsSSQiIhpLEomIiMaSRCIiorEkkYiIaOz/Ax1fHaeEsIBzAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "train angle  (71030, 1)\n",
            "train input speed  (71030, 20, 1)\n",
            "validation angle  (7893, 1)\n",
            "validation input speed  (7893, 20, 1)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Epoch 1/30\n",
            "3330/3330 [==============================] - 1476s 443ms/step - loss: 0.4575 - angle_out_loss: 0.0937 - speed_out_loss: 0.3638 - val_loss: 0.0915 - val_angle_out_loss: 0.0873 - val_speed_out_loss: 4.9859e-04\n",
            "saving model FMulti_model.h5 .............\n",
            "successfull saved to drive at ahmedaraby605@gmail.com\n",
            "Epoch 2/30\n",
            "3330/3330 [==============================] - 1442s 433ms/step - loss: 0.0820 - angle_out_loss: 0.0814 - speed_out_loss: 6.0157e-04 - val_loss: 0.0856 - val_angle_out_loss: 0.0815 - val_speed_out_loss: 4.4605e-04\n",
            "saving model FMulti_model.h5 .............\n",
            "successfull saved to drive at ahmedaraby605@gmail.com\n",
            "Epoch 3/30\n",
            "1565/3330 [=============>................] - ETA: 12:54 - loss: 0.0803 - angle_out_loss: 0.0797 - speed_out_loss: 5.9741e-04"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuPAFQb2Qy8f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def test_model_feed(generator):\n",
        "  batch = generator.__next__()\n",
        "  inp = batch[0]\n",
        "  out = batch[1]\n",
        "\n",
        "  images = inp[0]\n",
        "  angle = out[0]\n",
        "  print(images.shape)\n",
        "  plt.imshow(images[127])\n",
        "  print(angle[127])\n",
        "\n",
        "\n",
        "  def visualize_training_history(history):\n",
        "    \"\"\"with open(\"history.pickle\", 'rb') as f:\n",
        "      history = pickle.load(f)\"\"\"\n",
        "      \n",
        "    fig1 = plt.figure(1)\n",
        "    plt.plot(history['angle_out_loss'])\n",
        "    plt.plot(history['val_angle_out_loss'])\n",
        "    fig2 = plt.figure(2)\n",
        "    plt.show()\n",
        "\n",
        "    fig2 = plt.figure(2)\n",
        "    plt.plot(history['speed_out_loss'])\n",
        "    plt.plot(history['val_speed_out_loss'])\n",
        "    plt.legend(['speed',  'val_speed'])\n",
        "\n",
        "    plt.xlabel(\"epoch\")\n",
        "    plt.ylabel(\"accuracy\")\n",
        "    plt.title(\"train , val accuracy \")\n",
        "    plt.show()\n",
        "\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-A2GIicdsEZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "3a6b444f-d8ad-4398-a2fc-23df413d40ef"
      },
      "source": [
        "\"\"\"\n",
        "new settigns :\n",
        "1 - tanh \n",
        "2 - not regularization \n",
        "3 - all augmentation \n",
        "4 - no pretraining \n",
        "5 - only track2 \n",
        "6 - speed sampling trick\n",
        "7 - learning rate = 0.001\n",
        "\"\"\""
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nnew settigns :\\n1 - tanh \\n2 - not regularization \\n3 - all augmentation \\n4 - no pretraining \\n5 - only track2 \\n6 - speed sampling trick\\n7 - learning rate = 0.001\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    }
  ]
}